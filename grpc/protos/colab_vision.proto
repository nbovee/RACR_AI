syntax = "proto3";


service colab_vision {
    rpc constantInference(stream Info_Chunk) returns (stream Response_Dict);
}

// must sent that it is starting new inference
// bytes of inference to perform
// mark when inference complete
// receive results

message Info_Chunk{
    string id = 1; //uuid for the inference to avoid conflicts
    Chunk chunk = 2; //byte chunk, potentiall compressed with blosc
    repeated Action action = 3; //actions associated with this id & layer
    int32 layer = 4; //layer the chunks belong to. Inference would result in tensor for layer + 1. Layer of 0 indicates that a PIL(?) image is being sent.
}

message Response_Dict{
    string id = 1; //uuid to match test results
    map<string, float> keypairs = 2; //this is where we pass timing results. Yes they are a default option, but I want more flex
    bytes results = 3; //not sure what form these should take yet (due to how we would need to handle Yolo), so we will assemble an object from bytes for now
    repeated Action actions = 4; //currently the only important flag is ACT_COMPRESSED, but for large results will still be needed
}

enum Action {
    ACT_UNK = 0; //noop
    ACT_RESET = 1; //start new inference package with this chunk.
    ACT_APPEND = 2; //indicates that this layers chunks are used for future inference.
    ACT_INFERENCE = 3; //indicates inference can begin using this chunk.
    ACT_END = 4; //end current session
    ACT_COMPRESSED = 5; //this flag indicates the chunk series needs to be uncompressed with blosc
}

message Chunk{
    bytes chunk = 1;
}
